# 3장 평가 방법론

## 파운데이션 모델 평가의 과제

- 파운데이션 모델 평가가 어려운 이유 <br>
  (1) AI 모델이 똑똑해질수록 평가가 더 어려워짐
    - 초등학교 수학 문제 풀이는 누구나 틀렸는지 알 수 있다. 박사 수준의 문제 풀이라면? <br>
	(2) 파운데이션 모델은 개방형 모델이다
    - 전통적인 ML : 폐쇄형 모델. 분류 모델의 경우 출력 가능한 응답의 가짓수가 정해져 있다
    - 파운데이션 모델 : 개방형 모델. 올바른 응답이 너무 많다 <br>
  (3) "블랙박스"
    - 파운데이션 모델의 상세한 구조는 여러 이유로 인해 파악이 불가능함(개발자가 비공개, 사용자의 지식 부족 등) <br>
  (4) 모델을 평가할 벤치 마크 구성도 쉽지 않다
    - 파운데이션 모델의 발전 속도가 너무 빠름 : 좋은 평가 벤치 마크를 구성해도 수년 내에 포화 상태에 도달 <br>
  (5) 파운데이션 모델의 범용성
    - 하나의 모델이 이제 너무 많은 작업을 할 수 있다 : 평가 범위의 확장
      
- AI 분야에서 "평가" 에 대한 관심은 비약적으로 증가하였으나 여전히 다른 분야에 비하면 턱없이 부족함

![image](https://github.com/user-attachments/assets/f4296b30-c028-4f09-b755-6def7e1224ce)

## 언어 모델링 지표 이해

- 파운데이션 모델은 언어 모델을 기반으로 발전하였기 때문에 언어 모델에 대한 평가 지표는 여전히 유용하게 사용 가능함

### Entropy

- 엔트로피(Entropy)는 토큰이 평균적으로 얼마나 많은 정보를 전달하는지를 측정
- 아래 그림에서 정사각형 내의 위치를 설명하고자 함
- (a)와 같이 두 개의 토큰만 있는 경우 위치는 위/아래 2개 토큰 뿐. 토큰이 두 개뿐이므로 이를 나타내는 데 1비트면 충분함
- (b)와 같이 네 개의 토큰이 있는 경우 위치를 표현하기 위해 2비트가 필요
- 직관적으로 엔트로피는 언어에서 다음에 오는 것을 예측하기가 얼마나 어려운지를 측정

![image](https://github.com/user-attachments/assets/08565c98-2a79-4ad1-a308-7bd7f027be1e)

### Cross Entropy

- 데이터 세트에서 언어 모델을 훈련할 때 목표는 모델이 이 훈련 데이터의 분포를 학습하도록 하는 것
- 데이터 세트에서 언어 모델의 교차 엔트로피는 언어 모델이 이 데이터 세트에서 다음에 오는 것을 예측하기가 얼마나 어려운지를 측정
- 학습 데이터에 대한 모델의 교차 엔트로피는 두 가지 품질에 따라 달라집니다.
  - 학습 데이터의 엔트로피로 측정되는 학습 데이터의 예측 가능성
  - 언어 모델에 의해 포착된 분포가 학습 데이터의 실제 분포와 얼마나 다른지
- 따라서 Cross Entropy는 다음과 같다. $H(P, Q) = H(P) + D_{KL}(P || Q)$ .
- 언어 모델이 학습 데이터를 완벽하게 학습할 경우 교차 엔트로피는 학습 데이터의 엔트로피 $H(P)$와 정확히 같아진다

### BPC/BPB(문자당 비트 및 바이트당 비트)

- 언어 모델의 교차 엔트로피가 6비트이면 이 언어 모델은 각 토큰을 나타내는 데 6비트가 필요
- 서로 다른 모델은 서로 다른 토큰화 방법을 사용하므로 토큰당 비트 수는 모델 간에 비교할 수 없음
- 이를 보완하고자 한 지표가 BPC : 토큰당 비트 수가 6이고 평균적으로 각 토큰이 2개의 문자로 구성되면 BPC는 6/2 = 3
- BPC는 문자 인코딩 방식이 다를 경우 비교 불가 : ASCII에서는 각 문자가 7비트를 사용하여 인코딩, UTF-8에서는 문자가 8비트에서 32비트 사이를 사용하여 인코딩
- 이를 보완하고자 한 지표가 BPB : 언어 모델이 학습 데이터의 1바이트를 나타내는 데 필요한 비트 수. BPC가 3이고 각 문자가 7비트 또는 7/8바이트이면 BPB는 3 / (7/8) = 3.43입니다.

### 퍼플렉시티

- 실제 분포 P를 가진 데이터 세트가 주어지면 그 퍼플렉시티는 다음과 같이 정의됨 : $*PPL* (*P*) =  $2^{H(P)}$
- 교차 엔트로피가 모델이 다음 토큰을 예측하기 얼마나 어려운지를 측정한다면, 퍼플렉시티는 다음 토큰을 예측할 때 갖는 불확실성의 양을 측정
- 위 그림의 (b)에서 모델의 교차 엔트로피는 2비트. 이 때 정사각형의 위치를 예측한다면 4개의 가능한 옵션 중에서 선택해야함. 따라서 이 언어 모델의 퍼플렉시티는 4.
- 예시에선 엔트로피의 단위로 비트를 사용했으나 자연상수(e)도 많이 사용함

### 퍼플렉시티 해석 및 사용 사례

- 더 구조화된 데이터는 퍼플렉시티가 작다 : 데이터가 구조화될수록 예측이 더 쉽다
- 어휘(vocabulary)가 많을수록 퍼플렉시티가 크다 : 가능한 토큰이 많을수록 예측이 더 어렵다
- 컨텍스트 길이가 길수록 퍼플렉시티가 낮다 : 모델이 더 많은 컨텍스트를 가질수록 다음 토큰 예측에 대한 불확실성이 줄어든다

> [!CAUTION]
>
> 퍼플렉시티는 SFT 및 RLHF와 같은 기술을 사용하여 사후 훈련된(Post-trained) 모델을 평가하는 데 좋은 대리 변수가 아닐 수 있습니다.
> 사후 훈련은 모델에게 작업을 완료하는 방법을 가르치는 것입니다.
> 모델이 작업을 완료하는 데 능숙해짐에 따라 다음 토큰을 예측하는 데는 서툴러질 수 있습니다.
> 언어 모델의 퍼플렉시티는 일반적으로 사후 훈련 후 증가합니다.
> 어떤 사람들은 사후 훈련이 엔트로피를 *붕괴(collapses)*시킨다고 말합니다.
> 마찬가지로 모델의 숫자 정밀도와 메모리 공간을 줄이는 기술인 양자화(Quantization)도 모델의 퍼플렉시티를 예상치 못한 방식으로 변경할 수 있습니다.

- 텍스트에 대한 모델의 퍼플렉시티는 이 모델이 이 텍스트를 예측하기 얼마나 어려운지를 측정. 주어진 모델에 대해 퍼플렉시티는 모델이 훈련 중에 보고 기억한 텍스트에 대해 가장 낮다.
- 따라서 퍼플렉시티는 텍스트가 모델의 훈련 데이터에 있었는지 여부를 감지하는 데 사용할 수 있으며, 이는 데이터 오염을 감지하는 데 유용.
- 벤치마크 데이터에 대한 모델의 퍼플렉시티가 낮으면 이 벤치마크가 모델의 훈련 데이터에 포함되었을 가능성이 높으므로 이 벤치마크에 대한 모델의 성능은 덜 신뢰할 수 있다.
- 이는 또한 훈련 데이터의 중복 제거에도 사용할 수 있음 : 새 데이터의 퍼플렉시티가 높은 경우에만 기존 훈련 데이터 세트에 새 데이터를 추가
- 퍼플렉시티는 예측 불가능한 텍스트, 예를 들어 특이한 아이디어를 표현하는 텍스트("내 개는 여가 시간에 양자 물리학을 가르친다")나 횡설수설("집 고양이 가 눈")에 대해 가장 높아 비정상적인 텍스트 감지에 사용될 수 있다.

